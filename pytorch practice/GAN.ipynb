{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3cd5d8d-cc85-4bb8-886b-c44d9ed31a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fce5086a990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56570d1-8380-4fe5-81eb-680f5e52625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    \n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d9009b-6644-44b7-b101-4f27019a4eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3eeb54-be73-422c-8054-e877304632da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, im_dim = 784, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim*2),\n",
    "            get_generator_block(hidden_dim*2, hidden_dim*4),\n",
    "            get_generator_block(hidden_dim*4, hidden_dim*8),\n",
    "            nn.Linear(hidden_dim*8, im_dim), \n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, noise):   \n",
    "        return self.gen(noise)\n",
    "    \n",
    "    def get_gen(self):\n",
    "        \n",
    "        return self.gen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e5bfa1-04cc-4c17-9d4d-d3c0d5c92cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    return torch.randn(n_samples, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80902888-c302-4624-85c8-ebf47cd311b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Discriminator Block\n",
    "    Function for returning a neural network of the discriminator given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a discriminator neural network layer, with a linear transformation \n",
    "          followed by an nn.LeakyReLU activation with negative slope of 0.2 \n",
    "          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f6f140-2e51-48ea-a1fa-07f6c250e665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim = 784, hidden_dim = 128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            get_discriminator_block(im_dim, hidden_dim*4),\n",
    "            get_discriminator_block(hidden_dim*4, hidden_dim*2),\n",
    "            get_discriminator_block(hidden_dim*2, hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1))\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.disc(image)\n",
    "            \n",
    "    def get_disc(self):\n",
    "        return self.disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a091f11c-c579-44b3-8846-0fcf8204d64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "\n",
    "train_dataset = dsets.FashionMNIST(root = './data', download = True, transform = transforms.ToTensor())\n",
    "\n",
    "dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2791b60-af0a-4728-a14f-e994f5f72b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr = lr)\n",
    "\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39084985-4ab8-40a6-be7d-d1074f9d9e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n  Lossfake =−(target×log(prediction)+(1−target)×log(1−prediction))\\n\\nFake predictions: [0.2, 0.8, 0.6, 0.3, 0.9]\\nTarget label: 0 (indicating fake)\\n\\nUsing binary cross-entropy loss, the formula for each element of the loss is:\\nLossfake=−(target×log\\u2061(prediction)+(1−target)×log\\u2061(1−prediction))\\nLossfake\\u200b=−(target×log(prediction)+(1−target)×log(1−prediction))\\n\\nLet's calculate the loss for each fake image:\\n\\n    For the first prediction (0.2):\\n    Loss1= −(0×log\\u2061(0.2)+(1−0)×log\\u2061(1−0.2)) ≈ 0.223\\n\\n    For the second prediction (0.8):\\n    Loss2= −(0×log\\u2061(0.8)+(1−0)×log\\u2061(1−0.8)) ≈ 0.223\\n\\n\\n    For the third prediction (0.6):\\n    Loss3= −(0×log\\u2061(0.6)+(1−0)×log\\u2061(1−0.6)) ≈ 0.511\\n\\n    For the fourth prediction (0.3):\\n    Loss4= −(0×log\\u2061(0.3)+(1−0)×log\\u2061(1−0.3)) ≈ 0.357\\n\\n    For the fifth prediction (0.9):\\n    Loss5= −(0×log\\u2061(0.9)+(1−0)×log\\u2061(1−0.9)) ≈ 0.105\\n\\nNow, we'll take the average of these losses to get the overall fake loss.\\n         Average Loss ≈ 0.2838\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "  Lossfake =−(target×log(prediction)+(1−target)×log(1−prediction))\n",
    "\n",
    "Fake predictions: [0.2, 0.8, 0.6, 0.3, 0.9]\n",
    "Target label: 0 (indicating fake)\n",
    "\n",
    "Using binary cross-entropy loss, the formula for each element of the loss is:\n",
    "Lossfake=−(target×log⁡(prediction)+(1−target)×log⁡(1−prediction))\n",
    "Lossfake​=−(target×log(prediction)+(1−target)×log(1−prediction))\n",
    "\n",
    "Let's calculate the loss for each fake image:\n",
    "\n",
    "    For the first prediction (0.2):\n",
    "    Loss1= −(0×log⁡(0.2)+(1−0)×log⁡(1−0.2)) ≈ 0.223\n",
    "\n",
    "    For the second prediction (0.8):\n",
    "    Loss2= −(0×log⁡(0.8)+(1−0)×log⁡(1−0.8)) ≈ 0.223\n",
    "\n",
    "\n",
    "    For the third prediction (0.6):\n",
    "    Loss3= −(0×log⁡(0.6)+(1−0)×log⁡(1−0.6)) ≈ 0.511\n",
    "\n",
    "    For the fourth prediction (0.3):\n",
    "    Loss4= −(0×log⁡(0.3)+(1−0)×log⁡(1−0.3)) ≈ 0.357\n",
    "\n",
    "    For the fifth prediction (0.9):\n",
    "    Loss5= −(0×log⁡(0.9)+(1−0)×log⁡(1−0.9)) ≈ 0.105\n",
    "\n",
    "Now, we'll take the average of these losses to get the overall fake loss.\n",
    "         Average Loss ≈ 0.2838\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ac8f522-78ea-4cfe-b868-67ba3b8756b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen img shape:  torch.Size([5, 784])\n",
      "disc tensor shape:  torch.Size([5, 1])\n",
      "tensor([[-0.4969],\n",
      "        [-0.3424],\n",
      "        [-0.1927],\n",
      "        [-0.4492],\n",
      "        [-0.7467]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.4989, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fake_noise = get_noise(5, z_dim, device)\n",
    "fake = gen(fake_noise).detach()\n",
    "print(\"gen img shape: \", fake.shape)\n",
    "disc_fake_pred = disc(fake)\n",
    "print(\"disc tensor shape: \", disc_fake_pred.shape)\n",
    "print(disc_fake_pred)\n",
    "disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "print(disc_fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d38cb18-a3ea-4786-82a7-48880f35705b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real, loss, num_images, z_dim, device):\n",
    "    \n",
    "    fake_noise = get_noise(num_images, z_dim, device)\n",
    "    fake = gen(fake_noise).detach()\n",
    "    \n",
    "    disc_fake_pred = disc(fake)\n",
    "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "                               \n",
    "    disc_real_pred = disc(real)\n",
    "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "    \n",
    "    disc_loss = (disc_fake_loss + disc_real_loss)/2.0\n",
    "    \n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5a4658-a409-447b-81c9-943a1bea720e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    \n",
    "    fake_noise = get_noise(num_images, z_dim)\n",
    "    \n",
    "    fake_images = gen(fake_noise)\n",
    "    \n",
    "    disc_fake_pred = disc(fake_images)\n",
    "    \n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3085251-d014-4065-9207-5e23cb0179fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True # Whether the generator should be tested\n",
    "gen_loss = False\n",
    "error = False\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        # Flatten the batch of real images from the dataset\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "\n",
    "        ### Update discriminator ###\n",
    "        # Zero out the gradients before backpropagation\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        # Calculate discriminator loss\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, criterion, cur_batch_size, z_dim, device=device)\n",
    "\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        # For testing purposes, to keep track of the generator weights\n",
    "        if test_generator:\n",
    "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
    "\n",
    "        ### Update generator ###\n",
    "        # Zero out the gradients.\n",
    "        gen_opt.zero_grad()\n",
    "        # Calculate the generator loss\n",
    "        #fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        #fake = gen(fake_noise)\n",
    "        #disc_fake_pred = disc(fake)\n",
    "        #gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
    "        # Backprop through the generator: update the gradients and optimizer.\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # For testing purposes, to check that your code changes the generator weights\n",
    "        if test_generator:\n",
    "            try:\n",
    "                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n",
    "                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n",
    "            except:\n",
    "                error = True\n",
    "                print(\"Runtime tests have failed\")\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d7a9d-fad0-40f6-bd83-136e1135cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
